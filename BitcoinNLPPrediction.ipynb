{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "293bbceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\schen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\schen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\schen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\schen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import snscrape\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "719139b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>51814.02734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/27/2021</td>\n",
       "      <td>51956.32813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/2022</td>\n",
       "      <td>47510.72656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/10/2022</td>\n",
       "      <td>44278.42188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/17/2022</td>\n",
       "      <td>43413.02344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/24/2022</td>\n",
       "      <td>38825.41016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/31/2022</td>\n",
       "      <td>42500.78516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2/7/2022</td>\n",
       "      <td>45661.17188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2/14/2022</td>\n",
       "      <td>44667.21875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2/21/2022</td>\n",
       "      <td>40005.34766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2/28/2022</td>\n",
       "      <td>45077.57813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3/7/2022</td>\n",
       "      <td>42465.67188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3/14/2022</td>\n",
       "      <td>42316.55469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3/21/2022</td>\n",
       "      <td>46827.54688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3/28/2022</td>\n",
       "      <td>48086.83594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4/4/2022</td>\n",
       "      <td>47106.14063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4/11/2022</td>\n",
       "      <td>42424.58984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4/18/2022</td>\n",
       "      <td>42893.58203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4/25/2022</td>\n",
       "      <td>40713.89063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5/2/2022</td>\n",
       "      <td>39902.94922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5/9/2022</td>\n",
       "      <td>34222.07422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5/16/2022</td>\n",
       "      <td>31305.34180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5/23/2022</td>\n",
       "      <td>30590.58594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5/30/2022</td>\n",
       "      <td>32249.86328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6/6/2022</td>\n",
       "      <td>31693.29102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6/13/2022</td>\n",
       "      <td>26795.58984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6/20/2022</td>\n",
       "      <td>21783.72461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6/27/2022</td>\n",
       "      <td>21478.08984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7/4/2022</td>\n",
       "      <td>22314.94141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7/11/2022</td>\n",
       "      <td>21600.64063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7/18/2022</td>\n",
       "      <td>24196.81836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7/25/2022</td>\n",
       "      <td>24572.58008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8/1/2022</td>\n",
       "      <td>23578.65039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8/8/2022</td>\n",
       "      <td>24974.91406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8/15/2022</td>\n",
       "      <td>25135.58984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>8/22/2022</td>\n",
       "      <td>21804.90820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8/29/2022</td>\n",
       "      <td>20542.64453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9/5/2022</td>\n",
       "      <td>21770.55273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>9/12/2022</td>\n",
       "      <td>22673.82031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9/19/2022</td>\n",
       "      <td>19674.63086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>9/26/2022</td>\n",
       "      <td>20338.45508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10/3/2022</td>\n",
       "      <td>20408.39258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10/10/2022</td>\n",
       "      <td>19889.14648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10/17/2022</td>\n",
       "      <td>19666.99414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10/24/2022</td>\n",
       "      <td>20988.39453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10/31/2022</td>\n",
       "      <td>21446.88672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>11/7/2022</td>\n",
       "      <td>21053.24609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>11/14/2022</td>\n",
       "      <td>17109.32422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>11/21/2022</td>\n",
       "      <td>16771.47461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>11/28/2022</td>\n",
       "      <td>17197.49805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date         High\n",
       "0   12/20/2021  51814.02734\n",
       "1   12/27/2021  51956.32813\n",
       "2     1/3/2022  47510.72656\n",
       "3    1/10/2022  44278.42188\n",
       "4    1/17/2022  43413.02344\n",
       "5    1/24/2022  38825.41016\n",
       "6    1/31/2022  42500.78516\n",
       "7     2/7/2022  45661.17188\n",
       "8    2/14/2022  44667.21875\n",
       "9    2/21/2022  40005.34766\n",
       "10   2/28/2022  45077.57813\n",
       "11    3/7/2022  42465.67188\n",
       "12   3/14/2022  42316.55469\n",
       "13   3/21/2022  46827.54688\n",
       "14   3/28/2022  48086.83594\n",
       "15    4/4/2022  47106.14063\n",
       "16   4/11/2022  42424.58984\n",
       "17   4/18/2022  42893.58203\n",
       "18   4/25/2022  40713.89063\n",
       "19    5/2/2022  39902.94922\n",
       "20    5/9/2022  34222.07422\n",
       "21   5/16/2022  31305.34180\n",
       "22   5/23/2022  30590.58594\n",
       "23   5/30/2022  32249.86328\n",
       "24    6/6/2022  31693.29102\n",
       "25   6/13/2022  26795.58984\n",
       "26   6/20/2022  21783.72461\n",
       "27   6/27/2022  21478.08984\n",
       "28    7/4/2022  22314.94141\n",
       "29   7/11/2022  21600.64063\n",
       "30   7/18/2022  24196.81836\n",
       "31   7/25/2022  24572.58008\n",
       "32    8/1/2022  23578.65039\n",
       "33    8/8/2022  24974.91406\n",
       "34   8/15/2022  25135.58984\n",
       "35   8/22/2022  21804.90820\n",
       "36   8/29/2022  20542.64453\n",
       "37    9/5/2022  21770.55273\n",
       "38   9/12/2022  22673.82031\n",
       "39   9/19/2022  19674.63086\n",
       "40   9/26/2022  20338.45508\n",
       "41   10/3/2022  20408.39258\n",
       "42  10/10/2022  19889.14648\n",
       "43  10/17/2022  19666.99414\n",
       "44  10/24/2022  20988.39453\n",
       "45  10/31/2022  21446.88672\n",
       "46   11/7/2022  21053.24609\n",
       "47  11/14/2022  17109.32422\n",
       "48  11/21/2022  16771.47461\n",
       "49  11/28/2022  17197.49805"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"BTC-USD (2).csv\")\n",
    "df = df[[\"Date\",\"High\"]]\n",
    "df = df.iloc[0:50]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e094baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(words): # used\n",
    "    lemmatized_words = []\n",
    "    for word in words:\n",
    "        tempList = []\n",
    "        for word2 in word:\n",
    "            tempList.append(wordlemmatizer.lemmatize(word2))\n",
    "        lemmatized_words.append(tempList)\n",
    "    return lemmatized_words\n",
    "\n",
    "def uniqueWord(w): # used \n",
    "    w2=[]\n",
    "    for word in w:\n",
    "        tempList=[]\n",
    "        for word2 in word:\n",
    "            if tempList.count(word2)<1:\n",
    "                    tempList.append(word2)\n",
    "        w2.append(tempList)\n",
    "    return w2\n",
    "\n",
    "def remove_special_characters(text): # used\n",
    "    regex = r'[^a-zA-Z0-9\\s]'\n",
    "    text = re.sub(regex,'',text)\n",
    "    return text\n",
    "\n",
    "def removeStopWord(word_text):  # used\n",
    "    filtered_sentence = [] \n",
    "    stop_words = set(stopwords.words('english'))   \n",
    "    for w in word_text:\n",
    "        tempList=[]\n",
    "        for x in w:\n",
    "            if x.lower() not in stop_words: \n",
    "                tempList.append(x)\n",
    "        filtered_sentence.append(tempList)\n",
    "    return filtered_sentence   \n",
    " \n",
    "def meanOfWord(model, sentence): # used\n",
    "#     posValue=nltk.pos_tag(sentence)\n",
    "    posList=['CD']\n",
    "    nounList=['NN','NNP','NNS','NNPS']\n",
    "    value=[]\n",
    "    count=0\n",
    "    noun=0\n",
    "    for word in sentence:\n",
    "        a=model.wv.most_similar(word)\n",
    "        temp=[]\n",
    "        for w in a:\n",
    "            temp.append(w[1])\n",
    "        posValue=nltk.pos_tag([word])\n",
    "#         print(posValue)\n",
    "        wordScore=np.mean(temp)\n",
    "        if posValue[0][1] in posList:\n",
    "            count=count+1\n",
    "        else:\n",
    "            valueIfNum=checkNum(word)\n",
    "            count=count+valueIfNum\n",
    "        if posValue[0][1] in nounList:\n",
    "            noun=noun + .25\n",
    "        value.append(wordScore)\n",
    "    return np.mean(value)+count+noun\n",
    "\n",
    "def checkNum(s):\n",
    "    l= ['1','2','3','4','5','6','7','8','9','0']\n",
    "    check =False\n",
    "\n",
    "    for i in s:\n",
    "        if i in l:\n",
    "            check = True\n",
    "            break\n",
    "    if check == True:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "Stopwords = set(stopwords.words('english'))\n",
    "wordlemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "97b35b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list =[] #store date with sentence score and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "592e9b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-25 23:59:53+00:00</td>\n",
       "      <td>@BTCBreadMan @TeslaAndDoge This is seperate fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-25 23:59:47+00:00</td>\n",
       "      <td>Steve bro,\\n\\nWhen are you going to stop looki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-25 23:59:39+00:00</td>\n",
       "      <td>@TheRealCarlG Is Bitcoin going to keep going u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-25 23:59:30+00:00</td>\n",
       "      <td>$HEART AT 0.22 $ already!! This is a beast coi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-25 23:59:29+00:00</td>\n",
       "      <td>@c_otto83 You're a Bitcoiner if you own Bitcoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5045</th>\n",
       "      <td>2022-12-21 23:47:41+00:00</td>\n",
       "      <td>ðŸ‘‹ A new block was found on the #Bitcoin networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046</th>\n",
       "      <td>2022-12-21 23:47:37+00:00</td>\n",
       "      <td>This #Bitcoin Bear Market is an opportunity to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5047</th>\n",
       "      <td>2022-12-21 23:47:30+00:00</td>\n",
       "      <td>Bitcoin is mixed https://t.co/w5eik3TME2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>2022-12-21 23:47:28+00:00</td>\n",
       "      <td>The notion that NFT Twitter, crypto in general...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049</th>\n",
       "      <td>2022-12-21 23:47:23+00:00</td>\n",
       "      <td>@BCBacker Can we do a poll plz if bitcoin is a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5050 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Datetime  \\\n",
       "0    2021-12-25 23:59:53+00:00   \n",
       "1    2021-12-25 23:59:47+00:00   \n",
       "2    2021-12-25 23:59:39+00:00   \n",
       "3    2021-12-25 23:59:30+00:00   \n",
       "4    2021-12-25 23:59:29+00:00   \n",
       "...                        ...   \n",
       "5045 2022-12-21 23:47:41+00:00   \n",
       "5046 2022-12-21 23:47:37+00:00   \n",
       "5047 2022-12-21 23:47:30+00:00   \n",
       "5048 2022-12-21 23:47:28+00:00   \n",
       "5049 2022-12-21 23:47:23+00:00   \n",
       "\n",
       "                                                   Text  \n",
       "0     @BTCBreadMan @TeslaAndDoge This is seperate fr...  \n",
       "1     Steve bro,\\n\\nWhen are you going to stop looki...  \n",
       "2     @TheRealCarlG Is Bitcoin going to keep going u...  \n",
       "3     $HEART AT 0.22 $ already!! This is a beast coi...  \n",
       "4     @c_otto83 You're a Bitcoiner if you own Bitcoi...  \n",
       "...                                                 ...  \n",
       "5045  ðŸ‘‹ A new block was found on the #Bitcoin networ...  \n",
       "5046  This #Bitcoin Bear Market is an opportunity to...  \n",
       "5047           Bitcoin is mixed https://t.co/w5eik3TME2  \n",
       "5048  The notion that NFT Twitter, crypto in general...  \n",
       "5049  @BCBacker Can we do a poll plz if bitcoin is a...  \n",
       "\n",
       "[5050 rows x 2 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating list to append tweet data to\n",
    "tweets_list = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2021-12-20 until:2021-12-26').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2021-12-27 until:2022-1-2').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-1-3 until:2022-1-9').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-1-10 until:2022-1-16').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-1-17 until:2022-1-23').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-1-24 until:2022-1-30').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-1-31 until:2022-2-6').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-2-7 until:2022-2-13').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-2-14 until:2021-2-20').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-2-21 until:2022-2-27').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-2-28 until:2022-3-06').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-3-07 until:2022-3-13').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-3-14 until:2022-3-20').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-3-21 until:2022-2-27').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-3-28 until:2022-4-03').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-4-04 until:2022-4-10').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-4-11 until:2022-4-17').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-4-18 until:2022-4-24').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-4-25 until:2022-5-1').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-5-02 until:2022-5-08').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-5-09 until:2022-5-15').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-5-16 until:2022-5-22').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-5-23 until:2022-5-29').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-5-30 until:2022-6-05').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-6-06 until:2022-6-12').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-6-13 until:2021-6-19').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-6-20 until:2022-6-26').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-6-27 until:2022-7-03').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-7-04 until:2022-7-10').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-7-11 until:2022-7-17').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-7-18 until:2022-7-24').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-7-25 until:2022-7-31').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-8-01 until:2022-8-07').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-8-08 until:2022-8-14').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-8-15 until:2022-8-21').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-8-22 until:2022-8-28').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-8-29 until:2022-9-04').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-9-05 until:2022-9-11').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-9-12 until:2022-9-18').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-9-19 until:2022-9-25').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-9-26 until:2022-10-02').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-10-03 until:2022-10-09').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-10-10 until:2022-10-16').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-10-17 until:2022-10-23').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-10-24 until:2022-10-30').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-10-31 until:2022-11-06').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-11-07 until:2022-11-13').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-11-14 until:2022-11-20').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-11-21 until:2022-11-27').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-11-28 until:2022-12-04').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-12-05 until:2022-12-11').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-12-12 until:2022-12-18').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('bitcoin is since:2022-12-19 until:2022-12-22').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.content])\n",
    "# Creating a dataframe from the tweets list above\n",
    "tweets_df = pd.DataFrame(tweets_list, columns=['Datetime', 'Text'])\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "47b266a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.043313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.035937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.033359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.025161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.007621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.018420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.226139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.226139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.055875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.025650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.010195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.007854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.010865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.008373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.013405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.030929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.025161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.032719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.073545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.043680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.033246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.020810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.045977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.038145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.020390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.017899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.068507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.015402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.032834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.017473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.045780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.215917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.005382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.042952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.025311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.015913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.015774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.035940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.015743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.055402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.025161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.017662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.035908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.013512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SentenceScore\n",
       "0        0.005001\n",
       "1        0.004710\n",
       "2        0.010417\n",
       "3        0.030845\n",
       "4        0.005165\n",
       "5        0.043313\n",
       "6        0.002309\n",
       "7        0.035937\n",
       "8        0.033359\n",
       "9        0.025161\n",
       "10       0.007621\n",
       "11       0.018420\n",
       "12       0.226139\n",
       "13       0.226139\n",
       "14       0.055875\n",
       "15       0.025650\n",
       "16       0.010195\n",
       "17       0.007854\n",
       "18       0.010865\n",
       "19       0.008373\n",
       "20       0.013405\n",
       "21       0.030929\n",
       "22       0.025161\n",
       "23       0.032719\n",
       "24       0.073545\n",
       "25       0.043680\n",
       "26       0.033246\n",
       "27       0.020810\n",
       "28       0.045977\n",
       "29       0.038145\n",
       "30       0.020390\n",
       "31       0.017899\n",
       "32       0.068507\n",
       "33       0.015402\n",
       "34       0.032834\n",
       "35       0.017473\n",
       "36       0.045780\n",
       "37       0.215917\n",
       "38       0.005382\n",
       "39       0.042952\n",
       "40       0.025311\n",
       "41       0.015913\n",
       "42       0.015774\n",
       "43       0.035940\n",
       "44       0.015743\n",
       "45       0.055402\n",
       "46       0.025161\n",
       "47       0.017662\n",
       "48       0.035908\n",
       "49       0.013512"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=[]\n",
    "for i, row in tweets_df.iterrows():\n",
    "    text = row['Text']\n",
    "    sentences = sent_tokenize(text) # 1: sent tokenize\n",
    "    text_noSpecial_character = remove_special_characters(str(text)) # 2: remove special character:\n",
    "    word_text = [[text_noSpecial_character for text_noSpecial_character in sentences.split()] for sentences in sentences] # 3: word token\n",
    "    stop_text= removeStopWord(word_text) # 4: remove stop words\n",
    "    unique_text= uniqueWord(stop_text)   # 5: remove duplicate words\n",
    "    lemma_text = lemmatize_words(unique_text) # 6: lemmatization\n",
    "\n",
    "    model = Word2Vec(lemma_text, min_count=1,sg=1)\n",
    "    \n",
    "    count = 0\n",
    "    for index, sentence in enumerate(lemma_text):\n",
    "        l = lemma_text.index(sentence)\n",
    "        meanScore= meanOfWord(model,sentence)\n",
    "#         print(str(labels[index])+ \":\"+ str(sentence)+ str(meanScore) )\n",
    "        if index == 0:\n",
    "            count = count + meanScore\n",
    "    \n",
    "    if (i  + 1) % 100 == 0:\n",
    "        WeekScore = count / 100\n",
    "        score.append(WeekScore)\n",
    "        count = 0\n",
    "    \n",
    "score_df = pd.DataFrame(score, columns=['SentenceScore'])\n",
    "score_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4347141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##NLP to rate the average tweet of the day, connect value to the next day high of btc, predict when to buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ca94ba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using the two dataframes created, I will combine them, and move to VSCODE to code in the correct python version for tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
